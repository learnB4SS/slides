---
title: "Bayesian Data <br>Analysis<br> for <br>Speech Sciences"
subtitle: "Application to regression"
author: "Timo Roettger, Stefano Coretta and Joseph Casillas"
institute: "LabPhon workshop"
date: "2021/07/05 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: ["hygge", "https://learnb4ss.github.io/b4ss-theme/css/b4ss.css", "https://learnb4ss.github.io/b4ss-theme/css/b4ss-fonts.css"]
    lib_dir: libs
    nature:
      beforeInit: ["https://learnb4ss.github.io/b4ss-theme/js/b4ss_xaringan.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9
---

```{r setup, include=FALSE}
options(htmltools.dir.version=F)
knitr::opts_chunk$set(fig.retina=2, cache=F, warning=F, message=F)
```

```{r xaringan-extra-all-the-things, echo=F, eval=F}
xaringanExtra::use_xaringan_extra(
  c("tile_view", "panelset", "editable"
    #"scribble", "search", "webcam"
    )
)
xaringanExtra:::use_freezeframe()
```

```{r, 'helpers', echo=F}
source(here::here("assets", "helpers.R"))
```

```{r, load_refs, echo=FALSE, cache=FALSE, warning=F, message=F}
bib <- ReadBib(here("assets", "b4ss_refs.bib"), check = FALSE)
ui <- "- "
```

class: title-slide-section-grey, middle
background-image: url(https://www.bellevuerarecoins.com/wp-content/uploads/bigstock-Coin-Flip-5807921.jpg)
background-size: contain
background-position: 100% 50%

# What is probability?

???

Before we get started I'd like to ask you to take a second and think about "probability". 

What does is it mean? 

What do you understand if somebody asks you the probability you are going to be on time?

What is the probability it will rain tomorrow?

Over the next two days we will be thinking about the notion of probability and how define it in light of the research that we do


---
background-image: url(libs/worldview.png)
background-size: contain
background-color: black

# .white[The world according to <br>frequentists]

???

A key reason for *why* we will talk about probability has to do with frequentism

You might have heard this term before, but if not, that's fine. 

I'm certain you already have a grasp of what it is. 

Over the next few days we will be thinking a lot about frequentism and comparing it directly with Bayesian methods. 

---
background-image: url(https://www.bellevuerarecoins.com/wp-content/uploads/bigstock-Coin-Flip-5807921.jpg)
background-size: contain
background-position: 100% 50%

# What is frequentism?

.pull-left[

- "Classical" statistics

- Population parameters are fixed, actually exist

- Probability refers to the long-run frequency of a given event

- A sample of data is the result of one of an infinite number of exactly repeated experiments

- Data are random, result from sampling a fixed population distribution

]

???

- So what is it?
- Frequentist statistics represent what most of us have always been doing
- It's a bit of a blanket term used to refer to "classical" statistics
- The frequentist view of probability is what leads to some of the odd definitions of the statistical machinery you already know, like confidence intervals
- A key idea is that population parameters, what we estimate when we do statistics, are fixed, actually exist

- Under this view, probability refers to the long-run frequency of a given event
- We can consider a sample of data as the result of one of an infinite number of exactly repeated experiments
- In this sense, the data are random, and result from sampling a fixed population distribution

- The key idea that I'd like you to keep in mind at this point is that this view of probability seems to be at odds with how we think/reason
- For example when we ask something like what is the probability it will rain tomorrow? (we aren't typically thinking about long term frequencies or exactly repeated experiments)
- We will be coming back to these ideas of *probability* and *frequentism*

---
class: center, middle

# What if...

### There isn't one true population parameter... <br>
--
but an entire distribution of parameters, some more plausible than others

???

But for now, consider this...

What if there isn't one *true* population parameter

What if instead there is an entire distribution of parameters, some more plausible than others

---
background-color: black
background-image: url(https://raw.githubusercontent.com/jvcasillas/media/master/rstats/memes/bayesian_bey.png)
background-size: contain
count: false

???

This idea is at the heart of Bayesian inference

---
class: middle, center

# Bayesian inference <br>is all about the posterior

???

One key idea that I'd like you to hold on to for right now is that Bayesian inference is all about what we call the posterior distribution

I'm going to spend the rest of my time in this brief presentation building up intuition about the posterior.

In other words, in Bayesian data analysis we produce/approximate a posterior distribution of possible parameters that we can then summarize in different ways to answer questions and quantify uncertainty

This is a fundamental difference with regard to frequentistism
That is to say, there is no posterior distribution in frequentist statistics, you only estimate 1 single value for a parameter

I am going to walk us through applying this idea to regression

---
class: middle

# .center[Applied to regression]

## .blue[Classical]: There is a single "true" line of best fit, and I'll give my best estimate of it.

--

## **Bayesian**: There is a distribution of lines of fit...some more plausible than others...and I'll give you samples from that distribution.

???

As many of us already know, in standard linear regression in a frequentist framework, we typically estimate what we call a line of best fit, either using OLS or maximum likelihood estimation

It's actually quite simple at it's core, we have some blob of data and we try to shove a line through it to describe it the best we can

Under a Bayesian framework, we derive a distribution of lines that are compatible with our data and our prior assumptions

Some of these lines are more plausible than others, so we can use standard methods to summarize and quantify uncertainty about them

Let's illustrate this to make it clear

---
class: middle

```{r, mtcars-ex, echo=F}
mod_f <-  lm(mpg ~ drat, data = mtcars)
mod_b <- brm(mpg ~ drat, data = mtcars, file = here("assets", "cars_b"))

cars_post <- as_tibble(mod_b) %>% select(int = b_Intercept, b = b_drat)

plot_base <- mtcars %>% 
  ggplot(., aes(x = drat, y = mpg)) + 
    geom_point(fill = b4ss_colors[[1]], pch = 21, stroke = 0.5, size = 3.5) + 
    labs(y = "y", x = "x") + 
    coord_cartesian(ylim = c(10, 35)) + 
    b4ss_bw(base_size = 18)

plot_f <- plot_base + 
  geom_smooth(method = lm, formula = "y ~ x", color = b4ss_colors[[2]], 
      fill = b4ss_colors[[1]], size = 2) + 
  labs(title = "Frequentist model", subtitle = "Line of best fit")
plot_b <- plot_base + 
  geom_abline(intercept = fixef(mod_b)[1, 1], slope = fixef(mod_b)[2, 1], 
    color = b4ss_colors[[2]], size = 2) + 
  labs(title = "Bayesian model", subtitle = "Most plausible line of best fit")
plot_b_20 <- plot_base + 
  geom_abline(data = sample_n(cars_post, 20), 
    aes(intercept = int, slope = b), color = b4ss_colors[[1]], alpha = 0.2) + 
  geom_abline(intercept = fixef(mod_b)[1, 1], slope = fixef(mod_b)[2, 1], 
    color = b4ss_colors[[2]], size = 2) + 
  labs(title = "Bayesian model", subtitle = "Median line +20 plausible lines")
plot_b_50 <- plot_base + 
  geom_abline(data = sample_n(cars_post, 50), 
    aes(intercept = int, slope = b), color = b4ss_colors[[1]], alpha = 0.2) + 
  geom_abline(intercept = fixef(mod_b)[1, 1], slope = fixef(mod_b)[2, 1], 
    color = b4ss_colors[[2]], size = 2) + 
  labs(title = "Bayesian model", subtitle = "Median line +50 plausible lines")
plot_b_200 <- plot_base + 
  geom_abline(data = sample_n(cars_post, 200), 
    aes(intercept = int, slope = b), color = b4ss_colors[[1]], alpha = 0.07) + 
  geom_abline(intercept = fixef(mod_b)[1, 1], slope = fixef(mod_b)[2, 1], 
    color = b4ss_colors[[2]], size = 2) + 
  labs(title = "Bayesian model", subtitle = "Median line +200 plausible lines")
```

```{r, cars-f-vs-cars-b1, echo=F, fig.width=13, fig.height=5.5}
plot_f + plot_spacer() 
```

???

This scatter plot represents a traditional linear regression with a line of best fit +/- standard error

---
class: middle
count: false

```{r, cars-f-vs-cars-b2, echo=F, fig.width=13, fig.height=5.5}
plot_f + plot_b 
```

???

If we plot this next to the most plausible line from a Bayesian regression we see essentially the same line

---
class: middle
count: false

```{r, cars-b-draws1, echo=F, fig.width=13, fig.height=5.5}
plot_b_20 + plot_spacer() + plot_spacer()
```

???

Here we plot the most plausible line along with 20 random draws of plausible lines

---
class: middle
count: false

```{r, cars-b-draws2, echo=F, fig.width=13, fig.height=5.5}
plot_b_20 + plot_b_50 + plot_spacer()
```

???

Here we plot the most plausible line along with 50 random draws of other plausible lines

---
class: middle
count: false

```{r, cars-b-draws3, echo=F, fig.width=13, fig.height=5.5}
plot_b_20 + plot_b_50 + plot_b_200
```

???

Here we plot the most plausible line along with 200 random draws of other plausible lines

---
class: middle

```{r, cars-f-vs-cars-b-2, echo=F, fig.width=13, fig.height=5.5}
plot_f + plot_b_200
```

???

Notice that we seem to converge on the same result, though we are not expressing our best guess of the "true" regression line, 

Instead we express uncertainty about the relationship by plotting the posterior distribution of lines that are compatible with our assumptions and the data

The orange line merely represents the line the appears more often in the posterior, thus we assume it is the most plausible outcome

We will build our first model in just a second, but first let's get to know the data set we will be using

---

# Get to know the data set

```{r, get-to-know-1}
dim(polite)
```

???

The data set we will be using in this workshop is from Winter XXXX

This study examined the effect of politeness on the realization of pitch

We can see that the data set has 27 columns (or variables) and 224 observations

---

```{r get-to-know-2, echo=F}
glimpse(polite)
```

???

We certainly won't be using all of the 27 variables, but we can see that Winter XXXX measured many things, such as F0 min, F0 sd, and F0 range, to name just a few

We are going to begin by exploring the variable articulation_rate

---
class: middle

```{r, ar-hist, fig.height=8, fig.width=14, echo=F}
ar_hist <- polite %>% 
  ggplot(., aes(x = articulation_rate)) + 
    geom_histogram(color = "black", fill = b4ss_colors[[2]], binwidth = 0.25) + 
    geom_point(aes(y = -1), 
      size = 5, alpha = 0.1, pch = 21, fill = "grey80") + 
    stat_pointinterval(aes(y = -2.5), .width = 0.95, point_size = 5, pch = 21, 
      point_fill = b4ss_colors[[2]]) + 
    labs(y = "Count", x = "Articulation rate", 
      title = "Distribution of articulation rate", 
      subtitle = "Raw data and mean ±SD") + 
    b4ss_bw(base_size = 28, base_family = "Times") 

ar_hist
```

???

We can use a histogram to get an idea of the distribution of the variable

---

# Get to know the data set

```{r, ar-hist-rep, fig.height=5, echo=F, out.extra='style="float:right"'}
ar_hist + b4ss_bw(base_size = 20, base_family = "Times") 
```

.pull-left[

Let's explore the `articulation_rate` variable

- N = `r length(polite$articulation_rate)`

- The range is `r range(polite$articulation_rate) %>% round(., 2)`. 

- The .blue[mean] is `r mean(polite$articulation_rate) %>% round(., 2)`. 

- The .RUred[SD] is `r sd(polite$articulation_rate) %>% round(., 2)`.

- The 95% quantiles are `r quantile(polite$articulation_rate, probs = c(0.025, 0.975)) %>% round(., 2)` 

]

--

.pull-left[

We'll fit an intercept only model:

$$
articulation\ rate \sim Normal(\mu, \sigma) \\
$$

.center[
```lm(articulation_rate ~ 1)```
]

]

???

We can use standard methods to describe the distribution of values for articulation_rate

For we example, we have 224 observations, which range from 3.38 to 12.16

The average articulation rate is 6.68 (SD = 1.16)

Now we will use this distribution in a simple linear model, the simplest model we can fit is an intercept only model 

An int-only model is essentially a flat line (slope of 0), the intercept will be the mean of the distribution

We will fit frequentist and bayesian versions of this model and compare

---

# Frequentist model

We'll fit an intercept only model. The mean `articulation_rate` is `r mean(polite$articulation_rate) %>% round(., 2)` ±`r sd(polite$articulation_rate) %>% round(., 2)` SD. 

--

```{r, ar-int-only-freq}
lm(articulation_rate ~ 1, data = polite) %>% summary()
```

???

The frequentist version is easily fit with the `lm` function. 

We specify the criterion on the left side of the `~` and put a 1 on the right side to specify an intercept only model

If we look at the summary of the model we see the estimate for the intercept is essentially the same as the mean of the articulation rate distribution

---

# Bayesian model

We'll fit an intercept only model. The mean `articulation_rate` is `r mean(polite$articulation_rate) %>% round(., 2)` ±`r sd(polite$articulation_rate) %>% round(., 2)` SD. 

--

```{r, ar-int-only-bayes-hold, eval=F}
brm(articulation_rate ~ 1, data = polite) %>% summary
```

```{r, ar-int-only-bayes, echo=F}
b_mod_00 <- brm(articulation_rate ~ 1, data = polite, 
  file = here("assets", "b_mod_00"))
summary(b_mod_00)
post_00 <- posterior_samples(b_mod_00)
```

???

We can fit the Bayesian version of this model using the brm function from the package `brms` (note the syntax is identical)

There are some under-the-hood defaults that I am completely ignoring for now (priors and likelihood). 
We will dedicate time to these as we move along.

Notice that one key difference is that this model estimated 2 parameters: the intercept and sigma (the mean and SD of the articulation rate distribution)

Also notice that the estimate are also essentially the same as the mean and SD we calculated before

---
class: title-slide-section-blue, middle, center

# So what's the difference?

???

At this point you might be saying to yourself "So what? The models are the same?" and you would have a good point. 

The information we have looked at in the summaries is essentially the same. 

The main difference, and the key take away from this section, is that the bayesian model provides a posterior distribution of values for the parameters it estimates, the intercept and sigma. 

Let's see what we can do with a posterior distribution

---

# Exploring the posterior

.pull-left[
```{r, ar-int-posterior, eval=F}
post_00 <- posterior_samples(b_mod_00)
```

```{r, ar-int-posterior-show, echo=F}
posterior_samples(b_mod_00) %>% select(-lp__) %>% slice(1:15)
```

]

???

I can turn the model object into a dataframe/tibble of the posterior using the as_tibble function (or posterior_samples)

Because of the default values in brms I have 4000 samples. 
Here I print the first 15

--

.pull-right[

- This posterior distribution has 4000 draws of mean and SD values that are compatible with our data

- The posterior is just like any other distribution of data

- We can analyze/summarize it however we want

```{r, ar-post-play}
mean(post_00$b_Intercept)

quantile(
  post_00$b_Intercept, 
  probs = c(0.025, 0.975)
  )
```

]

???

We can now use all of the mathematical tricks we have up our sleeve to describe the posterior distribution in any way we find meaningful. 

Here I calculate the mean value for the intercept samples as well as a 95% credible interval, but I can describe the posterior in any way I want

This is how we can quantify our uncertainty about the estimates the model generates

---
class: center, middle

```{r, ar-post-param-plot, echo=F, fig.height=8, fig.width=12}
post_00 %>% 
  select(-lp__) %>% 
  pivot_longer(cols = everything(), names_to = "Parameter", values_to = "Estimate") %>% 
  ggplot(., aes(x = Estimate, y = Parameter)) + 
    stat_halfeye() + 
    b4ss_bw(base_size = 26)
```

???

Here we describe the posterior distributions of the two model parameters in a single plot

This is a handy way to summarize a model

A key takeaway is that the peak of the distributions represents the value that is the most common

---
class: center, middle

```{r, ar-post-paramspace-plot, echo=F, fig.height=8, fig.width=12}
jp_plot <- post_00 %>%
  ggplot(., aes(x = b_Intercept, y = sigma)) + 
    geom_point(size = 3, pch = 16, alpha = 0.2, color = b4ss_colors[[1]]) + 
    geom_point(data = tibble(b_Intercept = median(post_00$b_Intercept), sigma = median(post_00$sigma)), 
      size = 7, pch = 21, fill = b4ss_colors[[2]]) + 
    labs(y = expression(sigma), x = c(expression(beta), "Intercept")) + 
    b4ss_bw(base_size = 26) 

ggExtra::ggMarginal(jp_plot, type = "histogram", fill = b4ss_colors[[1]])

```

???

Here is a scatter plot of the entire posterior distribution (4000 samples)

This is a handy way to visualize the posterior parameter space (we will come back to this) because (1) it emphasizes the fact that we are looking at a 2D space, a joint probability distribution, and (2) there are many estimates for b_Intercept and sigma that are essentially the same. 

When we have a lot of estimates that appear often in the posterior it implies that these values are more plausible

I've highlighted the *most* plausible combination of the intercept and sigma, the medians (i.e., the values that are in the middle of the distribution), with the orange point. 

We can think of the joint distribution as a mountain and the orange point represents the highest point

---
class: center, middle
background-color: black

```{r, ar-post-density-plot, echo=F, fig.height=8, fig.width=12}
dark_density <- post_00 %>%
  ggplot(., aes(x = b_Intercept, y = sigma)) + 
    stat_density_2d(geom = "raster", aes(fill = ..density..),
    n = 100, contour = FALSE, show.legend = F, contour_var = "ndensity") + 
    scale_fill_viridis_c(option = "A") + 
    labs(y = expression(sigma), x = c(expression(beta), "Intercept")) + 
    ggdark::dark_theme_gray(base_size = 24) 

dark_density
```

---
class: center, middle
background-color: black
background-image: url(./libs/dark_density_posterior.png)
background-size: contain

```{r, echo=F, eval=F}
rayshader::plot_gg(dark_density, width = 7, height = 5, multicore = TRUE, 
  scale = 150, zoom = 0.5, theta = 10, phi = 30, windowsize = c(800, 800), 
  shadow_intensity = 0.1)
Sys.sleep(0.2)
rayshader::render_snapshot(
  here("01_a2r_initial_demo", "libs", "dark_density_posterior.png"), 
  clear = TRUE, color = "black")
```

---

# Takeaways

.Large[
- There are primarily two camps in statistics: frequentists and Bayesians

- The two camps see probability in different ways

- **Bayesian statistics is all about the posterior**
]

???

- There are primarily two camps in statistics: frequentists and Bayesians
- The two camps see probability in different ways
- Frequentists: parameters are real/true, provide best estimate of it
- Bayesians: there are distributions of possible parameters, we summarize the distribution
- Bayesian statistics is all about the posterior

---
background-color: black
background-image: url(https://raw.githubusercontent.com/jvcasillas/media/master/rstats/memes/bayesian_bey.png)
background-size: contain

???

With this in mind, you are now on your way to becoming Bayesians

We will continue building intuitions about these core ideas

---
count: false
class: title-slide-final
background-image: url(https://raw.githubusercontent.com/learnB4SS/b4ss-theme/main/assets/Logo.png)
background-size: 275px
background-position: 50% 40%

# .white[Thank you]

<br><br><br><br><br><br><br><br><br><br><br><br>

### https://learnB4SS.github.io

|                                 |                         |
| ------------------------------: | :---------------------- |
| `r fa("twitter", fill = "red")` | .white[@TimoRoettger]   |
| `r fa("twitter", fill = "red")` | .white[@StefanoCoretta] |
| `r fa("twitter", fill = "red")` | .white[@jvcasill]       |

---
exclude: true

`r AutoCite(bib, "mcelreath2018statistical")`

---
class: title-slide-section-grey
# References

```{r, 'refs', results='asis', echo=FALSE, eval=T, cache=FALSE}
PrintBibliography(bib)
```
