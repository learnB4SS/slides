---
title: "Bayesian Data <br>Analysis<br> for <br>Speech Sciences"
subtitle: "Bayes theorem"
author: "Timo Roettger, Stefano Coretta and Joseph Casillas"
institute: "LabPhon workshop"
date: "2021/07/05 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: ["https://learnb4ss.github.io/b4ss-theme/css/b4ss.css", "https://learnb4ss.github.io/b4ss-theme/css/b4ss-fonts.css"]
    lib_dir: libs
    nature:
      beforeInit: ["https://learnb4ss.github.io/b4ss-theme/js/b4ss_xaringan.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```


background-image: url(libs/img/bg01.png)
background-size: contain

???

Okay let us put our tippy toes into probability land. I have learned that learning about Bayes inference is not intuitive so students often need a couple of attempts to really grasp it. This was true for me too. So if you feel a little overwhelmed during the following session, its okay. First of all, you do not have to be able to explain Bayes theorem (the scary thing we will try to approach now). Having heard it once or twice and being able to read up on it again is sufficient. I will try to signpost the important conceptual take-homes and if you grasp them, you are in great shape.

---
background-image: url(libs/img/bg02_03.png)
background-size: contain

???

I have recently moved to Norway. I have lived in a few places by now, but as it is with a new country, you have to get used to the weather. And that’s a biggy in Norway. One of the larger existential questions that keep me up at night are surrounding whether its going to rain or not. This can have very practical implications.

One morning I start wondering whether to take an umbrella with me before I leave the house. I have not yet been outside so I don’t really know what the weather looks like. Let’s assume whether it rains or not might be a coin toss based on my experience.

---
background-image: url(libs/img/bg02_03.png)
background-size: contain

???

However, as I gather my things I happen to stand in front of a large window and I notice some scary-looking dark clouds on the horizon. Based on this new information, I might reconsider my beliefs about whether it’ll rain or not. 

But what exactly do we mean when we talk about probability. You are probably all, like, duh dude, we all know what probability means. But the concept is not that trivial and when talking about inferential frameworks, it actual matters (because NHST and Bayesian inference operate on different notions of probability).

Intuitively speaking, the probability of an event (say whether it rains or not) is a number that represents the uncertainty associated with the event’s occurrence. In everyday life, people often use percentages to denote probabilities. For example, the probability that a fair coin will land heads is 50%. For a more convenient representation, mathematicians use the decimal 0.5 to refer to the same probability.

---
background-image: url(libs/img/bg04.png)
background-size: contain

???

Under this convention, an impossible event  would have a probability of 0 (equivalent to 0%). And an event certain to occur will have a probability of 1 (or 100%). An event whose occurrence has some degree of uncertainty will be assigned a real number between 0 and 1. The closer an event’s probability is to 1, the more likely it is that the event will occur, and vice versa. Thats all super boring for you of course, but bear with me. The conventional notation for expressing probabilities is P(Event), so here P(Rain).

Let’s assign some random probability to the event that it rains, say 30%. What does that mean?

---
background-image: url(libs/img/bg05.png)
background-size: contain

???

If P(“Rain”) = 0.3, my expectations for rain are equivalent to my expectations to draw a purple ball from a bag of 30 purple balls and 70 orange balls

How do we arrive at this probability? well maybe living where you live, 30% of the days it actually rains, while on 70% of the days, it does not. So knowing nothing else, just the frequency of rainy vs sunny days, my best guess is 0.3. Note that there is still plenty of uncertainty. It is not super unlikely to pull a purple ball out of the bag, meaning it will rain.
If I take the umbrella, and it doesn’t rain, the umbrella is just a nuisance to carry around. If it does rain and I don’t take it, I will be soaking wet… mhm mhm. What to do?

But that scenario is of course not particular realistic right? We usually have several sources of information we take into account when assessing probabilities. 

---
background-image: url(libs/img/bg06a.png)
background-size: contain

???

So I gather more evidence. I look outside of the window and see some scary looking dark clouds on the horizon. 

Now you can ask the question: “What is the probability of these dark clouds on the horizon, giventhat it will rain”. Here you aren’t simply interested in the general probability of seeing these dark clouds. You want to know the probability of those clouds relative to whether it rains or not. In probability theory, such probabilities are called conditional probabilities and the notation used for them looks like this:

Conditional probabilities expresses the probability that Event-1 will occur when you assume (or know) that Event-2 has already occurred.

[C] From my experience in Norway, these clouds mean trouble! Speaking in probabilities, i believe that the probability of seeing these clouds when it actually will rain are 80% and the [C] probability of seeing these clouds when it won’t rain, will be 20%.

--

background-image: url(libs/img/bg06b.png)
background-size: contain

--

background-image: url(libs/img/bg06c.png)
background-size: contain

---
background-image: url(libs/img/bg07.png)
background-size: contain

???

Do I change my guess? Do I change the probability that I assign to the event Rain, given that I see these dark clouds on the horizon? Does my estimated probability of rain change? And if so how? 

Type in chat what do you think is the probability of it raining after I have seen the dark clouds?

---
background-image: url(libs/img/bg08a.png)
background-size: contain

???

So the conditional probability that a random day with these dark clouds on the sky is going to be a rainy day, is 24 / 38, so around 63%. 

--

background-image: url(libs/img/bg08b.png)
background-size: contain

---
background-image: url(libs/img/bg09.png)
background-size: contain

???

So that means I update my initial believe in the probability of rain after having seen the dark clouds. Note that this actually makes my guess more uncertain. Before, I was fairly certain that sunny Norway won’t rain on my parade. After seeing the cloud, I am actually slightly more certain that it will rain, however it could go either way. 

So there are two important concepts so far. One is uncertainty that is how certain we are in a particular event. And the other is belief updating, referring to the fact that we change our beliefs in the probability of events based on new observations.

Now how did we actually arrive at this number? You probably guessed it, Bayes Theorem.

---
background-image: url(libs/img/bg10.png)
background-size: contain

???

In mathematics, true statements are called theorems. These are statements whose truth you can prove using logic. The Bayes’ theorem is named after the British statistician and philosopher Thomas Bayes who first discovered it

The general situation where Bayes’ theorem is relevant, and you might already see where this is all going, is when you have some hypothesis (uhu!), in our case that it is going to rain, and you see some evidence, dark clouds on the horizon, and you want to know the probability that the hypothesis holds given that the evidence is true. We can write this as P of H given E. As in, we’re restricting our view only to the possibilities where the evidence holds. Now how do we get there?

---
background-image: url(libs/img/bg11.png)
background-size: contain

???

The first relevant number is the probability that the hypothesis holds before considering
the new evidence. In our example, that was the 30/100, which came from considering the ratio of rainy days and sunny days. Right so we literally count the purple balls.
This is known as the prior. Our belief in the probability of rain before we have received any new evidence.

---
background-image: url(libs/img/bg12.png)
background-size: contain

???

After that, we needed to consider the proportion of rainy days that fit the dark clouds on the horizon; the
probability of seeing the evidence given that the hypothesis is true. Again, when you
see this vertical greenish bar, it means we’re talking about a proportion of a limited part of the
total space of possibilities, in this case, limited to the left slide where the hypothesis
holds. In the context of Bayes’ theorem, this value also has a special name, it’s
the “likelihood”.

---
background-image: url(libs/img/bg13.png)
background-size: contain

???

Similarly, we need to know how much of the other side of our space includes the evidence;
the probability of seeing the evidence given that our hypothesis is NOT true. Okay so we should have all we need now. Attention, it becomes slightly mathy now, but only a little bit and I will offer you a more spatial way of thinking about the upcoming formulas. Bear with me.

---
background-image: url(libs/img/bg14a.png)
background-size: contain

???

Remember what we just said. The Probability that our hypothesis is true (it rains) is 24 / 38. All those icons that have a green background. 

The total number of rainy days fitting the evidence, [C] 24, divided
by the total number of days fitting the evidence, [C] 24 + 14.

But where do these number come from? [C] Where does that 24 in the numerator come from? For short [C] its the product of prior and likelihood. It’s the total number of days (100), times the [C] prior probability of being a rainy day, so we have 100 days times 0.3. That gives us 30 total rainy days, [C] times the probability that one of those fits the evidence which was 0.8. So the prior times the likelihood goes into the numerator.

[C] That same number shows up again in the denominator (24), but we
need to add the proportion of days which are NOT rainy days multiplied by the proportion of those days which fit the evidence adding up to 38.

If we step away from the arbitrary chosen number of days, we are left with the more abstract representation purely in terms of probabilities. This, my friends, is Bayes’ theorem. And if you are confused, you are supposed to. If you are not confused you are a monster. This part of the presentation are more for a review at a later stage.

--

background-image: url(libs/img/bg14b.png)
background-size: contain

--

background-image: url(libs/img/bg14c.png)
background-size: contain

--

background-image: url(libs/img/bg14d.png)
background-size: contain

--

background-image: url(libs/img/bg14e.png)
background-size: contain

---
background-image: url(libs/img/bg15.png)
background-size: contain

???

You often see this big denominator on the right written more simply as P(E), the total probability
of seeing the evidence. 

Piling on one final bit of jargon, this final answer, the probability of the hypothesis given the evidence, that is what we call the “posterior”; it’s your belief about the probability of the hypothesis AFTER seeing the evidence.

---
background-image: url(libs/img/bg16.png)
background-size: contain

???

Here is the Bayes theorem again. With these neat little formula we can iteratively update our beliefs about probabilities.

---
background-image: url(libs/img/bg17a.png)
background-size: contain

???

For example, I could improve my guess even more by checking the forecast on using a weather app. So the posterior of the first iteration of belief updating (after seeing the cloud) will function as the prior for the upcoming update. [C] As Dennis Lindley famously said: “Today’s posterior is tomorrow’s prior” [C]

Now assume I have arrived at an 80% probability that it will rain. Big question:

--

background-image: url(libs/img/bg17b.png)
background-size: contain

--

background-image: url(libs/img/bg17c.png)
background-size: contain

---
background-image: url(libs/img/bg18.png)
background-size: contain

???

Do I bring my umbrella? This last question is an important one because based on an uncertain event and a few observations I might have to make a decision, I might have to act. Type in chat, what you would do?

Now this question prepares you for an important concept. Decision procedures. You are used to apply decision procedures after you have ran you analysis. If you find a p-value that is lower than 0.05, you call it significant and claim to have found an effect. And you do so with confidence. This is an inherent part of null-hypothesis signficance testing, but it is not inherent in Bayesian thinking. So for now, leave this baggage behind. 

